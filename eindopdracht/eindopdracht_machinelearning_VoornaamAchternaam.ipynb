{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "eindopdracht-machinelearning-VoornaamAchternaam.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjEE7imUTuAW",
        "outputId": "b8beb2a7-3bbc-4adc-a504-c290ff5995ac"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXY2TJfdQLED"
      },
      "source": [
        "# Inleiding\n",
        "\n",
        "## Data\n",
        "We hebben een synthetische datasets. Deze bestaat uit twee items (`left` en `right`), die elk een bepaalde beschrijving hebben (vijf features, samengevoegd tot één string), en een kolom `match` die aangeeft of de twee items een match zijn, of niet. De beschrijving bestaat uit technische codes en serienummers. \n",
        "\n",
        "## Probleem\n",
        "De klant wil graag weten, wanneer twee items hetzelfde zijn, om zo schaalvoordeel te kunnen behalen met de wereldwijde inkoop. Omdat er miljoenen items zijn, moet de klant efficient kunnen zoeken: gegeven 1 item, wat zijn de mogelijke matchende items?\n",
        "\n",
        "## Onze opdracht\n",
        "Onze taak is om een proof-of-concept te leveren voor een set synthetische data: wij gaan laten zien dat wij met behulp van deep learning een item-matcher kunnen bouwen, en in dat proces een vectorembedding voor items genereren (wat je item2vec kan noemen; daarover verderop meer).\n",
        "\n",
        "## Motivatie voor Deep Learning\n",
        "Dit probleem zou, voor deze bescheiden synthethische dataset, waarschijnlijk redelijk eenvoudig kunnen worden opgelost met wat handmatige feature engineering en een simpel model. De dataset van de klant is echter veel complexer (met beschrijvingen per item van over de 4000 karaters, en miljoenen items en duizenden regels die bepalen of iets een match is). Dit is daarom niet een eindmodel, maar een proof-of-concept: we proberen intuities te krijgen over of dit werkt, en wat beter of slechter werkt.\n",
        "\n",
        "Daarnaast kan een simpel model wellicht wel zeggen: deze twee items zijn een match. Maar om in een groep van miljoenen items te zoeken naar een match, zouden we dan voor een item ook miljoenen potentiele matches moeten testen. Wanneer we een model hebben dat een itembeschrijving omzet naar een Embedding, dan kunnen we veel sneller de omgeving van een item doorzoeken.\n",
        "\n",
        "## Structuur van de opdracht\n",
        "We gaan een siamees netwerk bouwen. Dat gaat er ruwweg zo uitzien:\n",
        "\n",
        "<img src=https://www.pyimagesearch.com/wp-content/uploads/2020/11/keras_siamese_networks_header.png width=700/>\n",
        "\n",
        "- We hebben *twee* inputs (in dit voorbeeld zijn dat afbeeldingen)\n",
        "- Elk item gaat door een feature extractor. In dit voorbeeld is dat een ConvNet genoemd. De feature extractor is een model op zichzelf, dat als output een embedding geeft (in dit voorbeeld een encoding genoemd) van een bepaald aantal dimensies (bijvoorbeeld 16). De beide items moeten door *hetzelfde* netwerk gaan.\n",
        "- Vervolgens wordt de afstand tussen die twee embeddings berekend, in dit voorbeeld een euclidian distance.\n",
        "- In dit voorbeeld wordt geeindigd met een sigmoid. Wij gaan dat iets anders aanpakken.\n",
        "\n",
        "Er zijn vijf onderdelen:\n",
        "\n",
        "* Opdracht 1: data preprocessing. We moeten de data vectoriseren, en datagenerators maken.\n",
        "\n",
        "* Opdracht 2: We bouwen een feature extractor.\n",
        "\n",
        "* Opdracht 3: We gebruiken de feature extractor om een siamees netwerk te bouwen.\n",
        "\n",
        "* Opdracht 4: Verbeter het basismodel\n",
        "\n",
        "* Opdracht 5: bonusvragen\n",
        "\n",
        "Opdrachten 1 t/m 4 testen de dingen die we tijdens de training hebben geoefend. Daar valt ook het nabouwen van een architectuur onder die ik je geef, ook al heb je die architectuur nog niet exact zo gezien.\n",
        "\n",
        "Opdracht 5 is een bonusvraag, waar je extra punten mee kunt scoren.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEdj1zRyQDSj"
      },
      "source": [
        "# Opdracht 1: Data verkennen en voorbereiden\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "R0fFdrWZ3Q8j",
        "outputId": "fbe44e8b-1bb3-4610-8b02-290d961bdd7d"
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/uashogeschoolutrecht/tmoi-ml-19/master/data/synthetic_data_bigvocab.csv'\n",
        "file = tf.keras.utils.get_file('data.csv', url)\n",
        "df = pd.read_csv(file)\n",
        "df"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/uashogeschoolutrecht/tmoi-ml-19/master/data/synthetic_data_bigvocab.csv\n",
            "1048576/1045352 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>left</th>\n",
              "      <th>right</th>\n",
              "      <th>match</th>\n",
              "      <th>rule</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>vj43__i1____i1____ixk4__cdo9__</td>\n",
              "      <td>mg0___i1____w46___l0____vj43__</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>vj43__dri57_i1____qo7___cdo9__</td>\n",
              "      <td>h1____vj43__hu68__i1____fs8___</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ao1___e17___ds90__vj43__ui1___</td>\n",
              "      <td>xa55__vj43__i1____n1____sz2___</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tyq0__hl3___hl3___vj43__i1____</td>\n",
              "      <td>byb9__vj43__i28___yj04__i1____</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i1____vj43__gx81__rr02__ixk4__</td>\n",
              "      <td>ixk4__i1____h3____vj43__m59___</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14581</th>\n",
              "      <td>k2____v72___zal81_f45___hl3___</td>\n",
              "      <td>e95___qto54_bx29__sef9__md40__</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14582</th>\n",
              "      <td>zal81_jy9___v72___qo7___zr6___</td>\n",
              "      <td>tvr11_jf4___fm2___fm2___jx84__</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14583</th>\n",
              "      <td>h99___po16__qto54_u4____tvr11_</td>\n",
              "      <td>w2____k2____f37___xrd55_ux87__</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14584</th>\n",
              "      <td>tvr11_fs8___yf5___xto84_n1____</td>\n",
              "      <td>ux54__byb9__ab50__j33___lp3___</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14585</th>\n",
              "      <td>a53___jsm0__f45___l0____tvr11_</td>\n",
              "      <td>w46___wad07_hl3___sef9__f37___</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14586 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 left  ...  rule\n",
              "0      vj43__i1____i1____ixk4__cdo9__  ...     0\n",
              "1      vj43__dri57_i1____qo7___cdo9__  ...     0\n",
              "2      ao1___e17___ds90__vj43__ui1___  ...     0\n",
              "3      tyq0__hl3___hl3___vj43__i1____  ...     0\n",
              "4      i1____vj43__gx81__rr02__ixk4__  ...     0\n",
              "...                               ...  ...   ...\n",
              "14581  k2____v72___zal81_f45___hl3___  ...  None\n",
              "14582  zal81_jy9___v72___qo7___zr6___  ...  None\n",
              "14583  h99___po16__qto54_u4____tvr11_  ...  None\n",
              "14584  tvr11_fs8___yf5___xto84_n1____  ...  None\n",
              "14585  a53___jsm0__f45___l0____tvr11_  ...  None\n",
              "\n",
              "[14586 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJGuY47EdOKG"
      },
      "source": [
        "## Beschrijving data\n",
        "Je ziet hierboven twee kolommen: `left` en `right`. Dit zijn de beschrijvingen van twee items. Er zijn vijf features, die zijn samengevoegd tot een lange string. Features zijn bijvoorbeeld: `vj43` of `i1`, dat wordt dan samengevoegd tot `vj43___i1_`. De data is al gepreprocessed, dus alles is lowercase letters of cijfers. Omdat de features van verschillende lengte zijn, is de tussenruimte opgevuld met een padding-karakter, een underscore: `_`.\n",
        "\n",
        "De kolom `match` is een boolean, die aangeeft of iets een match is, of niet. De kolom `rule` geeft aan, welke regel gebruikt is om een match te genereren.\n",
        "\n",
        "De dataset is nog niet geshuffeled, en ook niet gebalanceerd. Verken de data voor zover je dat nodig vindt om keuzes te maken.\n",
        "\n",
        "We gaan in deze opdracht de datasets voorbewerken, zodat de data klaar is om aan ons model gevoerd te worden. Dat mag op verschillende manieren, zolang het eindproduct maar datagenerators zijn.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPnqmT5SFkTX"
      },
      "source": [
        "# Opdracht 1a : Vectorisatie van de tokens\n",
        "\n",
        "Vectoriseer de input op *karkaterniveau*. In de les hebben we geexperimenteerd met vectorisatie op *woord*niveau (met `TextVectorization`) , en op *zins*niveau (met pretrained modellen). Nu willen we dus vectorisatie op *karakterniveau*: elke letter of cijfer moet worden omgezet in een integer. Ons model kan namelijk niet omgaan met letters, maar wel met cijfers. We hebben dus een mapping nodig van elk karakter naar een cijfer.\n",
        "\n",
        "Dat kan op meerdere manieren: het boek doet het met een tensorflow Tokenizer (zie hoofdstuk 16) maar je mag het ook op een andere manier doen. Zolang het de data maar geschikt maar als input voor een model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eY8mXJBdHXFp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyqCDvWlJtGE"
      },
      "source": [
        "Als je jezelf wilt controleren, kun je een string invoeren in je tokenizer en checken of er getallen uitkomen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPseyEB2be2Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdw0nOaPbQJk"
      },
      "source": [
        "\n",
        "## Opdracht 1b : datagenerators\n",
        "Onze datagenerator moet gevectoriseerde data genereren (dus integers in plaats van letters), en dan steeds een batch van tuples `(left, right)` en een label `y`. Het model moet namelijk per keer steeds een paar ontvangen (`left` en `right`) en gaat van dat paar leren, of ze een match zijn of niet.\n",
        "\n",
        "Als je perse het vectoriseren in je model zelf wilt stoppen, als layer, mag dat ook, maar dat hoeft niet.\n",
        "\n",
        "Een `left` of `right` item heeft dan een dimensionaliteit van `(batchsize x sequencelength)`, terwijl een label een dimensionaliteit van `(batchsize x 1)` heeft.\n",
        "\n",
        "Hint: Shuffle en split je dataset zoals je in een productieomgeving zou doen; zorg dus dat je geen data lekt, ook niet via jouw ogen / bewustzijn...\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4khVukR1lt1c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QXpwtE9K49A"
      },
      "source": [
        "Als je jezelf wilt testen, dan zou een `.take(1)` van je generator als x een tuple met als shape per item in je tuple `(batch x sequence)` moeten teruggeven en als y een shape `(32 x 1)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_98UKIyrWVo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u86vYsYdlgnx"
      },
      "source": [
        "# Opdracht 2 : Feature extractor\n",
        "\n",
        "We hebben bij de les over word-embeddings gezien, dat we de betekenis van woorden kunnen omzetten naar een vector. Woorden met dezelfde betekenis komen dan dichter bij elkaar te liggen in een multidimensionale ruimte (bijvoorbeeld van 16 dimensies, of 50, of 300).\n",
        "\n",
        "Dit wordt vaak word2vec genoemd. Er zijn ook sentence-embeddings, dan kun je spreken van sentence2vec. \n",
        "\n",
        "Onze \"taal\" in deze dataset is echter geen Engels, of Nederlands, maar een technische taal van serienummers en materiaalcodes. Elk item heeft een aantal van deze codes. Wij willen een item2vec gaan bouwen: dat gaan we uiteindelijk doen met een siamees netwerk. Maar eerst gaan we een feature_extractor bouwen, die als input een item krijgt in de vorm van een reeks cijfers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxgmo_0jz55L"
      },
      "source": [
        "- Definieer een functie, die als je hem aanroept een keras Model terugstuurt. Je model wordt nog niet ge-compile-d, dat gaan we pas doen bij het uiteindelijke siamese model. We genereren vooral een model, zodat we hetzelfde model kunnen hergebruiken voor het linker en rechter item.\n",
        "- Maak de functie zo, dat je verschillende argumenten kunt meegeven aan de extractor voor de verschillende lagen. Bijvoorbeeld voor de hoeveelheid embeddings etc.\n",
        "- De basisarchitectuur van je extractor zou er zo moeten uitzien:\n",
        "\n",
        "  1. Een inputlaag\n",
        "  2. Een Embedding laag\n",
        "  3. Een Conv1D met een aantal filters en default kernel van 3.\n",
        "  4. Een MaxPool1D met default stride 2\n",
        "  5. Een Dense layer met een relu activatie\n",
        "\n",
        "Geef je model een duidelijke naam mee (bijvoorbeeld 'extractor') zodat je hem later makkelijk uit je model kunt peuteren.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URbN70fK6MvU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmdV0SsgfIz_"
      },
      "source": [
        "Als je jezelf wilt testen: \n",
        "\n",
        "genereer een feature extractor met behulp van je functie. \n",
        "Wanneer je nu uit je generator een eerste batch van `(left, right)` items haalt, dan kun je één van die items (bijvoorbeeld de `left`) aan je extractor voeren. \n",
        "\n",
        "De input is dan bijvoorbeeld een left item met afmeting `(batch x sequencelength)` en de extractor geeft dan als output `(batch x dimensionaliteit_Dense)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cGz3cn-tpnj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46Z7sR2WPC_N"
      },
      "source": [
        "# Opdracht 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssGCbJrKjZDW"
      },
      "source": [
        "We gaan nu de feature extractor gebruiken in een siamese netwerk. Om dat te doen, gaan we de afstand berekenen tussen de twee vectoren. Dat kan als volgt, met de functie `tf.linalg.norm`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShY5mhYMji9t",
        "outputId": "9dbdd31b-175d-4b1a-924a-b771685e3008"
      },
      "source": [
        "links = np.random.rand(32, 16)\n",
        "rechts = np.random.rand(32, 16)\n",
        "distance_ = tf.linalg.norm(links - rechts, axis=1)\n",
        "distance_"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
              "array([1.30810323, 1.74697942, 1.37400658, 1.46573726, 1.1034742 ,\n",
              "       1.35723074, 1.71460417, 1.30288774, 1.75965259, 1.5224766 ,\n",
              "       1.6393335 , 1.41884316, 0.77631058, 1.21409383, 1.93551651,\n",
              "       1.74973759, 1.87968921, 1.71995256, 1.66067274, 1.42630478,\n",
              "       1.35025613, 1.79716576, 1.52016704, 1.18704161, 1.73246956,\n",
              "       1.10079436, 1.9983664 , 1.16001782, 2.16236654, 1.46571079,\n",
              "       1.794174  , 1.24890016])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ngb-c_xij9yg"
      },
      "source": [
        "Als je lang doortraint, zou je als afstand een 0 kunnen krijgen. Dat kan `NaN`'s geven. Je kunt je model daartegen beveiligen door te clippen. Onderstaande voorbeeldcode zorgt dat de distance minimaal tussen 1e-14 en 100 ligt. In het voorbeeld hieronder liggen geen getallen buiten die grens; pas de waardes maar eens aan om te zien hoe dit werkt."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L436Kb5yj5Ri",
        "outputId": "feaee4e7-a03e-48c2-af00-32183e3baa11"
      },
      "source": [
        "tf.clip_by_value(distance_, clip_value_min=1e-14, clip_value_max=100)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
              "array([1.30810323, 1.74697942, 1.37400658, 1.46573726, 1.1034742 ,\n",
              "       1.35723074, 1.71460417, 1.30288774, 1.75965259, 1.5224766 ,\n",
              "       1.6393335 , 1.41884316, 0.77631058, 1.21409383, 1.93551651,\n",
              "       1.74973759, 1.87968921, 1.71995256, 1.66067274, 1.42630478,\n",
              "       1.35025613, 1.79716576, 1.52016704, 1.18704161, 1.73246956,\n",
              "       1.10079436, 1.9983664 , 1.16001782, 2.16236654, 1.46571079,\n",
              "       1.794174  , 1.24890016])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKhg6Rf7lEQD"
      },
      "source": [
        "Definieer nu een functie, die een siamees netwerk teruggeeft.\n",
        "Je hebt hiervoor een functionele API nodig!\n",
        "\n",
        "Zorg dat je netwerk het volgende heeft:\n",
        "\n",
        "*   Twee inputs (een voor het linker, een voor het rechter item)\n",
        "*   genereer één keer een extractor via de functie die je in opdracht 2 hebt gemaakt.\n",
        "*   Process vervolgens zowel je linker als je rechter input met dezelfde extractor, zodat dezelfde gewichten worden gebruikt.\n",
        "*   Bereken de distance.\n",
        "*   Clip de distance.\n",
        "*   Reshape de distance zodat de output de vorm `(batch x 1)` heeft.\n",
        "*   Laat je functie een `Model` terugsturen met twee inputs `[left, right]` en een output `[distance]`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUtVGp_mOYSQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGfWoAxfNmRR"
      },
      "source": [
        "Maak nu een model (dat je siamese noemt) met de volgende features:\n",
        "- De juiste inputshape\n",
        "- De juiste vocab length voor je embedding\n",
        "- Een Embedding met dimensionaliteit 16\n",
        "- 8 convolutional filters\n",
        "- 16 units als output van de laatste Dense layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPYzWEchO818"
      },
      "source": [
        "siamese = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhcsk_mVms_W"
      },
      "source": [
        "Zoals je wellicht is opgevallen, stuurt ons model een distance terug. Dus als wij 32 keer een tuple `(left, right)` aan het model geven, krijgen we 32 keer een distance terug (met als shape `(batch x 1)`.\n",
        "\n",
        "In de afbeelding in het begin van de opdracht wordt de distance door een sigmoid gehaald en zo geclassificeerd. Maar dat hoeft niet: we kunnen ook een `contrastive_loss` gebruiken. [link naar tf documentatie](https://www.tensorflow.org/addons/api_docs/python/tfa/losses/contrastive_loss)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Myd1rcamPwEF"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow_addons as tfa\n",
        "siamese.compile(loss=[tfa.losses.contrastive_loss], optimizer=Adam()) # deze code gaat ervan uit dat je je model `siamese` hebt genoemd."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ah1NLRoOUxM"
      },
      "source": [
        "Train je model voor 20 epochs en evalueer de loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdxDcGLFQjQ9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-0kh3nmsq4C"
      },
      "source": [
        "# Opdracht 4: verbeter\n",
        "\n",
        "Kun je deze architectuur verbeteren? \n",
        "\n",
        "Beantwoord eerst de volgende vragen:\n",
        "\n",
        "1. Wat is de impact van het vergroten of verkleinen van het aantal embeddings?\n",
        "2. Wat is de impact van het vergroten of verkleinen van het aantal units in de laatste Dense layer?\n",
        "3. Hoe verhouden de dimensionaliteit van de embedding en het aantal units in de laatste Dense layer zich? Bijvoorbeeld als de een veel kleiner is dan de ander?\n",
        "4. Wat is de impact van het vergroten of verkleinen van het aantal filters in de Conv1D layer?\n",
        "\n",
        "\n",
        "Je zou dit basismodel substantieel moeten kunnen verbeteren: de val_loss kan makkelijk een factor 10 omlaag ten opzichte van het baseline model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9NH7kPzVgTc"
      },
      "source": [
        "\n",
        "\n",
        "1.   Antwoord\n",
        "2.   Antwoord\n",
        "3. Antwoord\n",
        "4. Antwoord\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmtXWuFMVfZx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvJcoz3sVftY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEmR9UeUVsjW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZgqByoM-FUk"
      },
      "source": [
        "# Opdracht 5 : Evalueer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYR_Zkxmn5Fo"
      },
      "source": [
        "We kunnen ons model op meerdere manieren evalueren.\n",
        "\n",
        "Een eerste vraag is: Als we een voorspelling doen met ons model, krijgen we een hoeveelheid afstanden terug. Is het inderdaad zo, dat de paren die een match zijn een lage afstand hebben? En de paren die geen match zijn, een grote afstand hebben?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w36Wo4D7aV8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-e0IpkYpThO"
      },
      "source": [
        "Een andere vraag is: kun je een precision-recall curve maken? Beschouw dan de distance als een threshold. \n",
        "\n",
        "Om dit te kunnen doen met sklearn, zul je de distance moeten aanpassen zodat hij als een threshold werkt zoals sklearn verwacht. Hiervoor moet je zowel de documentatie van de contrastive loss moeten bestuderen, als die van de precision_recall_curve van sklearn.\n",
        "\n",
        "Je kunt ook zelf iets maken: je hebt een distance, en contrastive_loss gebruikt standaard een margin van 1: dat betekent dat matches dichter dan een afstand 1 moeten zijn. Met deze informatie kun je zelf een threshold maken om te evalueren."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2zZiIUl6Zxw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATOvmlgbV4Ak"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rfj2Mr-vqUr3"
      },
      "source": [
        "# Bonus\n",
        "\n",
        "Er zijn verschillende dingen die je als bonus kunt onderzoeken. Wat suggesties:\n",
        "\n",
        "- Ben je in staat om de extractor uit je getrainde model te halen? Hint: kijk naar `.get_layer(naam)`, waarbij `naam` de naam van jouw extractor-laag is.\n",
        "\n",
        "\n",
        "- Tensorboard heeft een [embedding projector](https://projector.tensorflow.org). Kun je visualisatie maken van de embeddings die je met de extractor kunt maken die je uit je getrainde model hebt gehaald? Een andere optie is om sklearn te gebruiken, bijvoorbeeld [tsne](https://scikit-learn.org/stable/modules/manifold.html#t-sne)\n",
        "\n",
        "- Wellicht kun je wat meer exotische architecturen inbouwen? Bijvoorbeeld een residual unit, of een (variatie op) inception?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsOGgnjRtoTG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sd-QY_jHV4S7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Rb7aVMKV4b7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}